# PRD-001: Pipeline de Extracci칩n H칤brida de Documentos

**칄pica:** Fase 1: La Fundaci칩n del RAG - Extracci칩n y Persistencia de Datos
**Referencia:** Este documento detalla la implementaci칩n de la acci칩n m치s cr칤tica de la **Fase 1** descrita en el `ROADMAP_SaaS_Architecture.md`.
**Status:** Propuesto
**Autor:** Gemini
**Fecha:** 2025-09-19

---

## 1. Contexto y Problema a Resolver

**Problema:** El sistema actual depende exclusivamente de la API de GPT-4o Vision para extraer texto de los PDFs. Este enfoque ha demostrado ser poco fiable, lento y costoso. Produce un texto de baja fidelidad que a su vez provoca que la capa de an치lisis final "alucine" o genere res칰menes de baja calidad. Esto bloquea la capacidad del producto para aportar valor real y ser comercialmente viable.

**Objetivo:** Reemplazar el pipeline de extracci칩n actual por un **sistema h칤brido, robusto y eficiente**. El objetivo es producir un texto con una fidelidad cercana al 100% para cada p치gina del documento, sentando una base de datos fiable sobre la que se puedan construir todas las futuras funcionalidades de an치lisis, Q&A y, fundamentalmente, el sistema RAG.

## 2. Requisitos Funcionales (RF)

*   **RF-1: Clasificaci칩n de P치ginas:** El sistema debe ser capaz de analizar cada p치gina de un PDF de entrada y clasificarla como **"Texto-Dominante"** (la mayor칤a del contenido es texto digital nativo) o **"Imagen-Dominante"** (la mayor칤a del contenido es una imagen, un gr치fico complejo, o texto no nativo).

*   **RF-2: Extracci칩n de Texto Nativo:** Para las p치ginas clasificadas como "Texto-Dominante", el sistema **DEBE** usar una librer칤a local (`PyMuPDF`) para extraer el contenido de texto. Este m칠todo es el preferido por su velocidad, coste cero y m치xima precisi칩n.

*   **RF-3: Extracci칩n de Texto de Im치genes (OCR):** Para las p치ginas clasificadas como "Imagen-Dominante", el sistema **DEBE** renderizar la p치gina como una imagen de alta resoluci칩n y enviarla a un modelo de IA con capacidad de visi칩n (GPT-4o) para realizar un OCR de alta fidelidad.

*   **RF-4: Ensamblaje de Contenido:** El sistema **DEBE** consolidar los resultados de los diferentes m칠todos de extracci칩n en una 칰nica estructura de datos coherente. El formato final debe ser una lista de strings, donde cada string representa el texto completo de una p치gina, manteniendo el orden original del documento.

*   **RF-5: Aislamiento de Sesiones por Canal:** El sistema **DEBE** gestionar cada an치lisis como una sesi칩n 칰nica y aislada por canal de Slack. Esto es un prerrequisito para la persistencia y la funcionalidad multi-tenant.

    **Notas de Implementaci칩n T칠cnica (TASK_1.2):**
    *   En `app.py`, la variable global en memoria `user_sessions` ser치 renombrada a `channel_sessions` para reflejar la nueva l칩gica.
    *   Todas las lecturas y escrituras a este diccionario se refactorizar치n para usar `channel_id` como la clave principal en lugar de `user_id`. Esto afecta a las funciones `debug_sessions`, `perform_dataroom_analysis`, `handle_ask_command`, y `handle_reset_command`.
    *   Al inicio de la funci칩n `perform_dataroom_analysis`, se a침adir치 l칩gica para crear un directorio de sesi칩n si no existe, usando la ruta `/.datarooms/{channel_id}/`. Se usar치 la funci칩n `os.makedirs(path, exist_ok=True)`.

## 3. Requisitos No Funcionales (RNF)

*   **RNF-1 (Rendimiento):** El proceso de extracci칩n completo para un deck est치ndar de 20 p치ginas (mayoritariamente texto) no deber칤a superar los 15 segundos, excluyendo los tiempos de red de subida/bajada de ficheros.

*   **RNF-2 (Precisi칩n):** La extracci칩n de texto para p치ginas nativas debe tener una precisi칩n >99.9%. La precisi칩n del OCR para p치ginas gr치ficas debe ser >95%.

*   **RNF-3 (Coste):** El sistema debe ser econ칩micamente eficiente, minimizando las llamadas a la costosa API de Vision y reserv치ndola exclusivamente para las p치ginas que no pueden ser procesadas localmente.

*   **RNF-4 (Robustez):** El sistema debe gestionar de forma elegante los posibles errores durante el parseo de PDFs (ej. ficheros corruptos) y registrarlos adecuadamente sin interrumpir el flujo completo de an치lisis de un dataroom.

## 4. Historias de Usuario

*   **Como Analista de VC**, quiero que el sistema extraiga los datos de las tablas y los n칰meros de los gr치ficos con la misma precisi칩n que el texto de los p치rrafos, para asegurar que no se pierde ninguna m칠trica clave en el an치lisis.
*   **Como Product Owner**, quiero que el pipeline de extracci칩n sea fiable y predecible, para poder construir con confianza funcionalidades de RAG y Q&A sobre una base de datos s칩lida.
*   **Como Cliente (Fondo de Inversi칩n)**, quiero que el an치lisis sea r치pido y preciso, para poder tomar decisiones de inversi칩n informadas sin tener que revisar manualmente cada documento por miedo a que la IA se haya equivocado.

## 5. Criterios de Aceptaci칩n

*   **Dado** un PDF con texto nativo, **cuando** se procesa, **entonces** el texto extra칤do es una copia exacta del contenido del fichero.
*   **Dado** un PDF que contiene slides que son solo im치genes, **cuando** se procesa, **entonces** el sistema identifica esas p치ginas y utiliza la API de Vision para extraer el texto de ellas.
*   **Dado** un PDF mixto, **cuando** se procesa, **entonces** el log del sistema muestra claramente qu칠 p치ginas se procesaron con `PyMuPDF` y cu치les con la API de Vision.
*   **Dado** un PDF corrupto, **cuando** se procesa, **entonces** el sistema lo marca como err칩neo y contin칰a con el resto de documentos del dataroom sin fallar.
*   El objeto final devuelto por el procesador para un PDF exitoso contiene la clave `"pages"` con una lista de strings.

## 6. Fuera de Alcance (Para esta 칄pica)

*   La implementaci칩n del almacenamiento persistente de esta informaci칩n (ser치 abordado en la **Fase 1** junto a esto).
*   La implementaci칩n del "chunking" o la vectorizaci칩n del texto (ser치 abordado en la **Fase 2**).
*   Cualquier an치lisis o interpretaci칩n sem치ntica del contenido extra칤do. El 칰nico objetivo de esta 칠pica es la **extracci칩n de texto de alta fidelidad**.

---
### Technical Implementation Notes (TASK_1.3)

1.  **Objective**: Refactor `handlers/doc_processor.py` to replace the existing extraction logic with a hybrid model that combines local text extraction and a vision-based OCR fallback.

2.  **File to Modify**: `handlers/doc_processor.py`.

3.  **Core Logic Implementation (`_process_pdf` method)**:
    *   The method will accept a file path and file name.
    *   It will use `fitz.open(file_path)` to open the PDF document.
    *   It will iterate through each `page` of the document.
    *   For each page, it will attempt to extract native text using `page.get_text("text", sort=True)`.

4.  **Hybrid Heuristic**:
    *   A simple heuristic will be used to classify the page. If the extracted text's character count is greater than 100 (`len(page_text) > 100`), the page will be classified as **"Text-Dominant"**.
    *   If the character count is 100 or less, it will be classified as **"Image-Dominant"**, triggering the OCR fallback.

5.  **OCR Fallback Logic (`_get_ocr_for_image` method)**:
    *   When a page is deemed "Image-Dominant":
        *   A log message will indicate the fallback to Vision OCR.
        *   The page will be rendered as a high-resolution PNG image (e.g., 200 DPI) using `page.get_pixmap()`.
        *   The image will be saved to a temporary directory (e.g., `./temp/`).
        *   The `_get_ocr_for_image` helper method will be called with the path to the temporary image. This method uses the `gpt4o_processor` to send the image to the "gpt-4o" model with a specific OCR prompt.
        *   The text returned by the API will be appended to the list of page contents.
        *   The temporary image file will be deleted using `os.remove()`.

6.  **Final Output Structure**:
    *   The `_process_pdf` method will return a dictionary containing:
        *   `name`: The original file name.
        *   `type`: 'pdf'.
        *   `pages`: A list of strings, where each string is the full text of a page.
        *   `metadata`: A sub-dictionary including `extraction_method`, `pages_count`, `text_pages`, and `image_pages` to provide visibility into the process.

7.  **Error Handling**: The entire `_process_pdf` logic will be wrapped in a `try...except` block to gracefully handle file corruption or other processing errors, returning a structured error message without crashing.

---
### Technical Implementation Plan for TASK_1.4

1.  **Objective**: Persist the JSON output from the `DocumentProcessor` to disk.
2.  **File Format**: The output for each processed document will be saved as a separate `.json` file.
3.  **File Naming Convention**: The name of the JSON file will be derived from the original document's name, but with the `.json` extension. For example, `investor_deck.pdf` will become `investor_deck.pdf.json`.
4.  **Storage Location**: The JSON files will be stored inside the session directory that is already being created, i.e., `/.datarooms/{channel_id}/{file_name}.json`.
5.  **Implementation Details**:
    *   The `perform_dataroom_analysis` function in `app.py` will be modified.
    *   After the `doc_processor.process_dataroom_documents(downloaded_files)` call, a loop will iterate through the `processed_documents` list.
    *   For each `doc` in the list, the full output path will be constructed: `os.path.join(session_dir, f"{doc['name']}.json")`.
    *   `json.dump()` will be used to write the `doc` dictionary to the specified path.
    *   A log entry will be added to confirm the file has been saved, e.g., `logger.info(f"游 Saved extraction results to {output_path}")`.